{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data downloaded from https://ncg-task.github.io/data.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "from constants import BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_list(file_name):\n",
    "    \"\"\" Extract list of contributing sentences from sentences.txt in each sub-diretory\"\"\"\n",
    "    with open(file_name) as f:\n",
    "        lines = f.readlines()\n",
    "    sentence_list = [int(line) for line in lines]\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_sentence_target(file_name, sentence_list):\n",
    "    \"\"\" Get list of sentences and their target values for a given file in stanza format. \n",
    "        Target value 1=contributing sentence, 0=not contributing sentence \"\"\"\n",
    "    with open(file_name) as f:\n",
    "        lines = f.readlines()\n",
    "    sentences = []\n",
    "    sentences_target = []\n",
    "    line_count = 0\n",
    "    for line in lines:\n",
    "        if line.endswith('.\\n'):\n",
    "            line_count+=1\n",
    "            target = 1 if line_count in sentence_list else 0\n",
    "            sentences.append(line.strip())\n",
    "            sentences_target.append(target)\n",
    "            \n",
    "    return sentences, sentences_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_abstract(file_name):\n",
    "    \"\"\" Extract the abstract from given file in stanza format\"\"\" \n",
    "    with open(file_name) as f:\n",
    "        lines = f.readlines()\n",
    "    abstract = []\n",
    "    start_abstract = False\n",
    "    abstract_lines_count = 0\n",
    "    for line in lines:\n",
    "        if line.lower().strip() == 'abstract':\n",
    "            start_abstract = True\n",
    "            continue\n",
    "        if start_abstract:\n",
    "            if not line.strip().endswith('.') and abstract_lines_count > 2:\n",
    "                start_abstract = False\n",
    "                break\n",
    "            abstract_lines_count += 1\n",
    "            abstract.append(line.strip())\n",
    "    return ' '.join(abstract)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data from trial-data folder by looping through various sub-directories and convert into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>doc_path</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The reading comprehension task , that asks que...</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/rohantondulkar/Projects/Typeset/trial-d...</td>\n",
       "      <td>The reading comprehension task , that asks que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Recent formulations of this task have typicall...</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/rohantondulkar/Projects/Typeset/trial-d...</td>\n",
       "      <td>The reading comprehension task , that asks que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>However , Rajpurkar et al . ( 2016 ) recently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/rohantondulkar/Projects/Typeset/trial-d...</td>\n",
       "      <td>The reading comprehension task , that asks que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>In this paper , we focus on this answer extrac...</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/rohantondulkar/Projects/Typeset/trial-d...</td>\n",
       "      <td>The reading comprehension task , that asks que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>We show that scoring explicit span representat...</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/rohantondulkar/Projects/Typeset/trial-d...</td>\n",
       "      <td>The reading comprehension task , that asks que...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_num                                           sentence  target  \\\n",
       "0        0  The reading comprehension task , that asks que...       0   \n",
       "1        0  Recent formulations of this task have typicall...       1   \n",
       "2        0  However , Rajpurkar et al . ( 2016 ) recently ...       0   \n",
       "3        0  In this paper , we focus on this answer extrac...       1   \n",
       "4        0  We show that scoring explicit span representat...       0   \n",
       "\n",
       "                                            doc_path  \\\n",
       "0  /Users/rohantondulkar/Projects/Typeset/trial-d...   \n",
       "1  /Users/rohantondulkar/Projects/Typeset/trial-d...   \n",
       "2  /Users/rohantondulkar/Projects/Typeset/trial-d...   \n",
       "3  /Users/rohantondulkar/Projects/Typeset/trial-d...   \n",
       "4  /Users/rohantondulkar/Projects/Typeset/trial-d...   \n",
       "\n",
       "                                            abstract  \n",
       "0  The reading comprehension task , that asks que...  \n",
       "1  The reading comprehension task , that asks que...  \n",
       "2  The reading comprehension task , that asks que...  \n",
       "3  The reading comprehension task , that asks que...  \n",
       "4  The reading comprehension task , that asks que...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(BASE_DIR, 'trial-data')\n",
    "dirs = os.listdir(data_path)\n",
    "doc_sentence_list = {}\n",
    "sentences_text_list = []\n",
    "sentences_target_list = []\n",
    "doc_num_list = []\n",
    "doc_path_list = []\n",
    "abstract_list = []\n",
    "doc_num = 0\n",
    "for item in dirs:\n",
    "    if item != 'README.md' and item != '.DS_Store':\n",
    "        sub_dirs = os.listdir(os.path.join(data_path, item))\n",
    "        for sub_dir in sub_dirs:\n",
    "            if sub_dir == '.DS_Store':\n",
    "                continue\n",
    "            info_path = os.path.join(data_path, item, sub_dir)\n",
    "            sentences_file = os.path.join(info_path, 'sentences.txt')\n",
    "            sentence_list = get_sentences_list(sentences_file)\n",
    "            doc_sentence_list[doc_num] = sentence_list\n",
    "            for info_file in os.listdir(info_path):\n",
    "                if sub_dir == '.DS_Store':\n",
    "                    continue\n",
    "                if info_file.endswith('Stanza-out.txt'):\n",
    "                    stanza_out_text_path = os.path.join(info_path, info_file)\n",
    "                    sentences_text, sentences_target = get_document_sentence_target(stanza_out_text_path, sentence_list)\n",
    "                    sentences_text_list.extend(sentences_text)\n",
    "                    sentences_target_list.extend(sentences_target)\n",
    "                    doc_num_list.extend([doc_num] * len(sentences_target))\n",
    "                    doc_path_list.extend([stanza_out_text_path] * len(sentences_target))\n",
    "                    abstract = get_document_abstract(stanza_out_text_path)\n",
    "                    abstract_list.extend([abstract] * len(sentences_target))\n",
    "                    doc_num +=1\n",
    "                    break\n",
    "data_df = pd.DataFrame({'doc_num': doc_num_list, 'sentence': sentences_text_list, 'target': sentences_target_list,\n",
    "                       'doc_path': doc_path_list, 'abstract': abstract_list})\n",
    "data_df.to_csv(os.path.join(BASE_DIR, 'generated_data', 'data.csv'), index=False)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_practice]",
   "language": "python",
   "name": "conda-env-dl_practice-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
